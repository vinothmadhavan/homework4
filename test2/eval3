# sucess ones prev
class TransformerPlanner(nn.Module):
    def __init__(
        self,
        n_track: int = 10,
        n_waypoints: int = 3,
        d_model: int = 128,
    ):
        # super().__init__()

        # self.n_track = n_track
        # self.n_waypoints = n_waypoints

        # self.query_embed = nn.Embedding(n_waypoints, d_model)

        super().__init__()

        self.n_track = n_track
        self.n_waypoints = n_waypoints
        self.d_model = d_model

        # Embedding for the query (waypoints)
        self.query_embed = nn.Embedding(n_waypoints, d_model)

        # Linear layer to project input features to d_model
        self.input_proj = nn.Linear(4, d_model)  # 4 because we concatenate left and right (2+2)

        # Transformer decoder
        decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=8)
        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)

        # Output layer to project back to 2D waypoints
        self.output_proj = nn.Linear(d_model, 2)

    def forward(
        self,
        track_left: torch.Tensor,
        track_right: torch.Tensor,
        **kwargs,
    ) -> torch.Tensor:
        """
        Predicts waypoints from the left and right boundaries of the track.

        During test time, your model will be called with
        model(track_left=..., track_right=...), so keep the function signature as is.

        Args:
            track_left (torch.Tensor): shape (b, n_track, 2)
            track_right (torch.Tensor): shape (b, n_track, 2)

        Returns:
            torch.Tensor: future waypoints with shape (b, n_waypoints, 2)
        """

        # Concatenate the left and right track boundaries
        x = torch.cat((track_left, track_right), dim=2)  # Shape: (b, n_track, 4)

        # Project input to d_model
        x = self.input_proj(x)  # Shape: (b, n_track, d_model)

        # Prepare the query embeddings
        query_embed = self.query_embed.weight.unsqueeze(1).repeat(1, x.size(0), 1)  # Shape: (n_waypoints, b, d_model)

        # Transpose x to match the expected input shape for the transformer (n_track, b, d_model)
        x = x.permute(1, 0, 2)

        # Pass through the transformer decoder
        tgt = self.transformer_decoder(query_embed, x)  # Shape: (n_waypoints, b, d_model)

        # Transpose back to (b, n_waypoints, d_model)
        tgt = tgt.permute(1, 0, 2)

        # Project to 2D waypoints
        waypoints = self.output_proj(tgt)  # Shape: (b, n_waypoints, 2)

        return waypoints






===================


[INFO     00:03:668] Transformer Planner
C:\Users\divya\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\nn\functional.py:5560: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:555.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
[INFO     00:03:766]   - Test Output Shape                                  [ 5 / 5 ]
[WARNING  00:06:459]   - Longitudinal Error                                 [ 4 / 10 ]
[WARNING  00:06:459] longitudinal_error: 0.261
[WARNING  00:06:459]   - Longitudinal Error: Extra Credit                   [ 0 / 1 ]
[WARNING  00:06:459]   - Lateral Error                                      [ 0 / 10 ]
[WARNING  00:06:459] lateral_error: 2.040
[WARNING  00:06:459]   - Lateral Error: Extra Credit                        [ 0 / 1 ]
[WARNING  00:06:459]   - Driving Performance                                [ 0 / 10 ]
[WARNING  00:06:459] Skipping test (pystk not installed).
[INFO     00:06:459]  --------------------------------------------------    [   9 /  35 ]
[INFO     00:06:475] CNN Planner
[INFO     00:06:611]   - Test Output Shape                                  [ 5 / 5 ]
[INFO     00:10:439]   - Longitudinal Error                                 [ 10 / 10 ]
[WARNING  00:10:439] longitudinal_error: 0.184
[INFO     00:10:439]   - Longitudinal Error: Extra Credit                   [ 1 / 1 ]
[INFO     00:10:439]   - Lateral Error                                      [ 10 / 10 ]
[WARNING  00:10:439] lateral_error: 0.356
[INFO     00:10:439]   - Lateral Error: Extra Credit                        [ 1 / 1 ]
[WARNING  00:10:439]   - Driving Performance                                [ 0 / 5 ]
[WARNING  00:10:439] Skipping test (pystk not installed).
[INFO     00:10:439]  --------------------------------------------------    [  27 /  30 ]
[INFO     00:10:439] Total                                                     63 / 100
