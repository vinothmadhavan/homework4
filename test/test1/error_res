The error you're encountering is due to the fact that the `CNNPlanner` model's `forward` method expects an `image` tensor as input, but in your training script, you're calling the model with `track_left` and `track_right` tensors, which are meant for the `MLPPlanner` and `TransformerPlanner` models.

To fix this, you need to modify your training script to handle different input types based on the model being used. Here's how you can adjust your `train` function to accommodate the `CNNPlanner`:

1. **Check the model type**: Determine which model is being used and adjust the input data accordingly.

2. **Load the correct data**: For `CNNPlanner`, you should load image data instead of track boundaries.

Here's a modified version of your `train` function to handle different models:

```python
def train(exp_dir="logs", model_name="mlp_planner", num_epoch=10, lr=1e-3, batch_size=16, seed=2024):
    if torch.cuda.is_available():
        device = torch.device("cuda")
    else:
        print("CUDA not available, using CPU")
        device = torch.device("cpu")

    torch.manual_seed(seed)
    np.random.seed(seed)

    log_dir = Path(exp_dir) / f"{model_name}_{datetime.now().strftime('%m%d_%H%M%S')}"
    logger = tb.SummaryWriter(log_dir)

    model = load_model(model_name)
    model = model.to(device)
    model.train()

    # Load data based on the model type
    if model_name == "cnn_planner":
        train_data = load_data("drive_data/train", shuffle=True, batch_size=batch_size, num_workers=2, input_type="image")
        val_data = load_data("drive_data/val", shuffle=False, input_type="image")
    else:
        train_data = load_data("drive_data/train", shuffle=True, batch_size=batch_size, num_workers=2)
        val_data = load_data("drive_data/val", shuffle=False)

    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    for epoch in range(num_epoch):
        model.train()
        epoch_loss = 0.0

        for batch in train_data:
            if model_name == "cnn_planner":
                images = batch['image'].to(device)
                waypoints = batch['waypoints'].to(device)
                waypoints_mask = batch['waypoints_mask'].to(device)

                # Forward pass
                predicted_waypoints = model(image=images)
            else:
                track_left = batch['track_left'].to(device)
                track_right = batch['track_right'].to(device)
                waypoints = batch['waypoints'].to(device)
                waypoints_mask = batch['waypoints_mask'].to(device)

                # Forward pass
                predicted_waypoints = model(track_left=track_left, track_right=track_right)

            # Compute loss (e.g., MSE loss for regression)
            loss = nn.MSELoss()(predicted_waypoints, waypoints)

            epoch_loss += loss.item()

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        model.eval()
        with torch.no_grad():
            for batch in val_data:
                if model_name == "cnn_planner":
                    images = batch['image'].to(device)
                    waypoints = batch['waypoints'].to(device)

                    predicted_waypoints = model(image=images)
                else:
                    track_left = batch['track_left'].to(device)
                    track_right = batch['track_right'].to(device)
                    waypoints = batch['waypoints'].to(device)

                    predicted_waypoints = model(track_left=track_left, track_right=track_right)

                # Compute validation metrics if needed

        print(f"Epoch {epoch + 1}/{num_epoch}, Loss: {epoch_loss:.4f}")

        # Log metrics to TensorBoard
        logger.add_scalar('Loss/train', epoch_loss, epoch)

    save_model(model)
    torch.save(model.state_dict(), log_dir / f"{model_name}.th")
    print(f"Model saved to {log_dir / f'{model_name}.th'}")
```

In this code, I've added a check for the `model_name` to determine whether to load image data or track boundary data. The `load_data` function should be modified to accept an `input_type` parameter, which specifies whether to load images or track boundaries. Make sure your dataset loading function can handle this parameter and return the appropriate data.
